{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "flipped_path = r'E:\\cyshield\\heatmap classification\\training\\right'\n",
    "not_flipped_path = r'E:\\cyshield\\heatmap classification\\training\\wrong'\n",
    "\n",
    "validation_right_path = r'E:\\cyshield\\heatmap classification\\validation\\right'\n",
    "validation_wrong_path = r'E:\\cyshield\\heatmap classification\\validation\\wrong'\n",
    "def load_and_preprocess_data(image_path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(image_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            img = cv2.imread(os.path.join(image_path, filename))\n",
    "            img = cv2.resize(img, (100, 100))\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "flipped_images, flipped_labels = load_and_preprocess_data(flipped_path, 'flipped')\n",
    "not_flipped_images, not_flipped_labels = load_and_preprocess_data(not_flipped_path, 'not_flipped')\n",
    "\n",
    "all_images = flipped_images + not_flipped_images\n",
    "all_labels = flipped_labels + not_flipped_labels\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels_encoded = label_encoder.fit_transform(all_labels)\n",
    "\n",
    "all_images, all_labels_encoded = shuffle(all_images, all_labels_encoded, random_state=42)\n",
    "\n",
    "val_right_images, val_right_labels = load_and_preprocess_data(validation_right_path, 'flipped')\n",
    "\n",
    "val_wrong_images, val_wrong_labels = load_and_preprocess_data(validation_wrong_path, 'not_flipped')\n",
    "\n",
    "val_images = val_right_images + val_wrong_images\n",
    "val_labels = val_right_labels + val_wrong_labels\n",
    "\n",
    "val_labels_encoded = label_encoder.transform(val_labels)\n",
    "\n",
    "all_images = np.array(all_images)/255.0\n",
    "val_images = np.array(val_images)/ 255.0\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(all_images, all_labels_encoded, epochs=10, validation_data=(val_images, val_labels_encoded))\n",
    "val_loss, val_acc = model.evaluate(val_images, val_labels_encoded)\n",
    "print(val_acc)\n",
    "model.save('flipped_detection_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
