{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rembg import remove \n",
    "import os\n",
    "from PIL import Image \n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_largest_id_card(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #Retrieve all non black pixels (discard the background)\n",
    "    _, binary_mask = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_area = 0.0\n",
    "    largest_contour = None\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            largest_contour = contour\n",
    "\n",
    "    if largest_contour is not None:\n",
    "        peri = cv2.arcLength(largest_contour, True)\n",
    "        epsilon = 0.02 * peri\n",
    "        rectangle_points = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
    "        return rectangle_points\n",
    "\n",
    "    return None\n",
    "\n",
    "def rotate_image(image, angle, scale=1.0):\n",
    "    rows, cols = image.shape[:2]\n",
    "    \n",
    "\n",
    "    center = (cols / 2, rows / 2)\n",
    "\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated_image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    return rotated_image\n",
    "\n",
    "def rotate_points(points, angle, center):\n",
    "    points_array = np.array(points, dtype=np.float32)\n",
    "    points_array -= center\n",
    "    theta = np.radians(angle)\n",
    "    rotation_matrix = np.array([[np.cos(theta), np.sin(theta)],\n",
    "                                [-np.sin(theta), np.cos(theta)]])\n",
    "    rotated_points = np.dot(points_array, rotation_matrix.T)\n",
    "    rotated_points += center\n",
    "    #original format (list of tuples)\n",
    "    rotated_points_list = rotated_points.reshape((-1, 2)).tolist()\n",
    "    return rotated_points_list\n",
    "    \n",
    "def sort_points(pre_sort_points):\n",
    "        sorted_points = sorted(pre_sort_points, key=lambda p: p[0])\n",
    "        left_side = sorted_points[:2]\n",
    "        right_side = sorted_points[2:]\n",
    "        top_left = min(left_side, key=lambda p: p[1])\n",
    "        bottom_left = max(left_side, key=lambda p: p[1])\n",
    "        top_right = min(right_side, key=lambda p: p[1])\n",
    "        bottom_right = max(right_side, key=lambda p: p[1])\n",
    "        sorted_rectangle_points = [top_left, top_right, bottom_left, bottom_right]\n",
    "        return sorted_rectangle_points\n",
    "def fix_orientation(image,list_points,sorted_rectangle_points):\n",
    "    # fontScale \n",
    "    fontScale = 1\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    color = (255, 0, 0) \n",
    "    thickness = 2\n",
    "    if list_points is not None:\n",
    "        x, y, w, h = cv2.boundingRect(list_points)\n",
    "        #cropped_id_card = image[y:y + h, x:x + w]  \n",
    "        rot_angle = 0\n",
    "        while True:\n",
    "            rotated_image = rotate_image(image,rot_angle)\n",
    "            rotated_points = rotate_points(sorted_rectangle_points, rot_angle,(w // 2, h // 2))\n",
    "            #cv2.drawContours(rotated_image, [np.array(rotated_points, dtype=np.int32)], 0, (0, 255, 0), 2)\n",
    "            if abs(rotated_points[0][1] - rotated_points[1][1])>10 and abs(rotated_points[2][1] - rotated_points[3][1])>10:    \n",
    "                if rotated_points[0][1] < rotated_points[1][1] and rotated_points[2][1] < rotated_points[3][1]:\n",
    "                    rot_angle += 1\n",
    "                else:\n",
    "                    rot_angle-=1\n",
    "                \n",
    "            else:\n",
    "                distance_01 = np.linalg.norm(np.array(rotated_points[0]) - np.array(rotated_points[1]))\n",
    "                distance_02 = np.linalg.norm(np.array(rotated_points[0]) - np.array(rotated_points[2]))\n",
    "\n",
    "                if distance_02 > distance_01:\n",
    "                    rot_angle += 90 \n",
    "                else:\n",
    "                    rot_angle = rot_angle *1.04\n",
    "\n",
    "                rotated_image = rotate_image(image, rot_angle)\n",
    "                rotated_points = rotate_points(sorted_rectangle_points, rot_angle, (w // 2, h // 2))\n",
    "                # for i, point in enumerate(rotated_points):\n",
    "                #     rotated_image = cv2.putText(rotated_image, str(i), tuple(map(int, point)), font,  \n",
    "                #                                 fontScale, color, thickness, cv2.LINE_AA) \n",
    "                return rotated_image\n",
    "\n",
    "def run_rotation_fix(path):\n",
    "    fontScale = 1\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    color = (255, 0, 0) \n",
    "    thickness = 2\n",
    "    image = cv2.imread(path)\n",
    "    image = remove(image) \n",
    "    # cv2.imshow('Rotated Image', image)\n",
    "    list_points = find_largest_id_card(image)\n",
    "    if list_points is None:\n",
    "        #print('resized')\n",
    "        image = cv2.resize(image, (1500, 1500))\n",
    "        list_points = find_largest_id_card(image)\n",
    "    #print(list_points)\n",
    "    \n",
    "    # for i, point in enumerate(list_points):\n",
    "    #     print(point[0])\n",
    "    #     image = cv2.putText(image, str(i),  (point[0]), font,  \n",
    "    #             fontScale, color, thickness, cv2.LINE_AA) \n",
    "\n",
    "    list_points = list_points.copy().reshape((4, 2))\n",
    "    sorted_rectangle_points = sort_points(list_points)\n",
    "    # for i, point in enumerate(sorted_rectangle_points):\n",
    "    #     print(point[0])\n",
    "    #     image = cv2.putText(image, str(i),  tuple(map(int, point)), font,  \n",
    "    #             fontScale, color, thickness, cv2.LINE_AA) \n",
    "\n",
    "    # cv2.imshow('Original Image', image)\n",
    "    # cv2.waitKey(0)  # Wait for any key press\n",
    "\n",
    "\n",
    "\n",
    "    rotated_image = fix_orientation(image,list_points,sorted_rectangle_points)\n",
    "        \n",
    "    base_name = os.path.splitext(os.path.basename(path))[0]\n",
    "    output_path = os.path.join(base_name,'result0.jpg')\n",
    "    cv2.imwrite(output_path, rotated_image)\n",
    "    return(rotated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN for upside down rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(image):\n",
    "    image = image[:, :, :3]\n",
    "    image = cv2.resize(image, (100, 100))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    return image\n",
    "def flip_check(image_path):\n",
    "    model_path = 'flipped_detection_model.h5'\n",
    "    model = load_model(model_path)\n",
    "    input_image = preprocess_image(image_path)\n",
    "    prediction = model.predict(input_image)\n",
    "    if prediction[0][0] >= 0.5:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# image = cv2.imread(r'D:\\Lines Segments_Abdalla Mohialdin_Cyshield\\image1\\result1.jpg')\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "# #edge detection\n",
    "# edges = cv2.Canny(blurred, 0, 150)\n",
    "\n",
    "# cv2.imshow('z',edges)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def detect_remove_edges(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_mask = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    max_area = 0.0\n",
    "    largest_contour = None\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            largest_contour = contour\n",
    "\n",
    "    if largest_contour is not None:\n",
    "        peri = cv2.arcLength(largest_contour, True)\n",
    "        epsilon = 0.02 * peri\n",
    "        rectangle_points = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
    "        if len(rectangle_points) == 4:\n",
    "            x, y, w, h = cv2.boundingRect(rectangle_points)\n",
    "            cropped_id_card = image[y:y + h, x:x + w]\n",
    "            flipped = flip_check(cropped_id_card)\n",
    "            if flipped:\n",
    "                cropped_id_card = rotate_image(cropped_id_card, 180)\n",
    "            return cropped_id_card[20:-50, 10:-20]\n",
    "    return None\n",
    "def detect_id_card(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    #edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    return edges\n",
    "\n",
    "\n",
    "\n",
    "def detect_and_highlight(image_canny,image_path):\n",
    "\n",
    "    cropped_image = detect_remove_edges(image_canny)\n",
    "    if cropped_image is None:\n",
    "\n",
    "        image_canny = cv2.resize(image_canny, (1500, 1500))\n",
    "        cropped_image = detect_remove_edges(image_canny)\n",
    "    #print(cropped_image)\n",
    "    \n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    #print(base_name)\n",
    "    output_path = os.path.join(base_name,'result1.jpg')\n",
    "    cv2.imwrite( output_path, cropped_image)\n",
    "    #print(output_path)\n",
    "\n",
    "    edges = detect_id_card(cropped_image)\n",
    "\n",
    "    output_path2 = os.path.join(base_name,'result2.jpg')\n",
    "    cv2.imwrite(output_path2, edges)\n",
    "    return edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-processing for info extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dilating_image(image):\n",
    "\n",
    "    binary_image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    #remove noise\n",
    "    median_filtered_image = cv2.medianBlur(binary_image, 3)\n",
    "\n",
    "    edges = edge_detection(median_filtered_image)\n",
    "    dilated_image = custom_dilation(edges)\n",
    "\n",
    "    return dilated_image\n",
    "\n",
    "\n",
    "def edge_detection(image):\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    morph_image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "    edges = cv2.Canny(morph_image, 50, 150)\n",
    "\n",
    "    return edges\n",
    "\n",
    "def custom_dilation(image):\n",
    "    #dilation_kernel = np.array([[0, 1, 0],\n",
    "                                # [1, 1, 1],\n",
    "                                # [0, 1, 0]], dtype=np.uint8)\n",
    "    dilation_kernel = np.ones((1, 11), np.uint8)\n",
    "    dilated_image = cv2.dilate(image, dilation_kernel, iterations=4)\n",
    "\n",
    "    return dilated_image\n",
    "\n",
    "\n",
    "def pre_process_before_detection(output_image,image_path):\n",
    "    preprocessed_image = dilating_image(output_image)\n",
    "    # cv2.imshow('original', cv2.imread(image_path))\n",
    "    # cv2.imshow('preprocessed', preprocessed_image)\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    output_path = os.path.join(base_name,'result3.jpg')\n",
    "    cv2.imwrite(output_path,preprocessed_image)\n",
    "    return preprocessed_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_intersection(rect1, rect2):\n",
    "    x1, y1, w1, h1 = rect1\n",
    "    x2, y2, w2, h2 = rect2\n",
    "\n",
    "    x_intersection = max(0, min(x1 + w1, x2 + w2) - max(x1, x2))\n",
    "    y_intersection = max(0, min(y1 + h1, y2 + h2) - max(y1, y2))\n",
    "\n",
    "    intersection_area = x_intersection * y_intersection\n",
    "    area_rect1 = w1 * h1\n",
    "    area_rect2 = w2 * h2\n",
    "    if area_rect1 < area_rect2:\n",
    "        intersection_percent = intersection_area / area_rect1\n",
    "    else:\n",
    "        intersection_percent = intersection_area / area_rect2\n",
    "    #iou = intersection_area / float(area_rect1 + area_rect2 - intersection_area)\n",
    "    return intersection_percent\n",
    "\n",
    "def merge_overlapping_rectangles(rectangles):\n",
    "    if not rectangles:\n",
    "        return []\n",
    "\n",
    "    merged_rectangles = [rectangles[0]]\n",
    "\n",
    "    for current_rect in rectangles[1:]:\n",
    "        #check occlusion for the new merged rectangle\n",
    "        intersection = calculate_intersection(current_rect, merged_rectangles[-1])\n",
    "\n",
    "        if intersection >= 0.4: \n",
    "            merged_rectangles[-1] = (\n",
    "                min(merged_rectangles[-1][0], current_rect[0]),\n",
    "                min(merged_rectangles[-1][1], current_rect[1]),\n",
    "                max(merged_rectangles[-1][0] + merged_rectangles[-1][2], current_rect[0] + current_rect[2]) - min(merged_rectangles[-1][0], current_rect[0]),\n",
    "                max(merged_rectangles[-1][1] + merged_rectangles[-1][3], current_rect[1] + current_rect[3]) - min(merged_rectangles[-1][1], current_rect[1])\n",
    "            )\n",
    "        else:\n",
    "            merged_rectangles.append(current_rect)\n",
    "\n",
    "    return merged_rectangles\n",
    "\n",
    "def highlight_rectangles(image,main_image):\n",
    "\n",
    "    min_rectangle_area=4000\n",
    "    _, binary_mask = cv2.threshold(image, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    rectangles = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w * h > min_rectangle_area:\n",
    "            rectangles.append((x, y, w, h))\n",
    "\n",
    "    merged_rectangles = merge_overlapping_rectangles(rectangles)\n",
    "\n",
    "\n",
    "    highlighted_image = main_image.copy()\n",
    "\n",
    "    for rect in merged_rectangles:\n",
    "        x, y, w, h = rect\n",
    "        cv2.rectangle(highlighted_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    return highlighted_image, merged_rectangles\n",
    "\n",
    "def detection_and_segmentation(image,image_path):\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    main_image_path = os.path.join(base_name, 'result1.jpg')\n",
    "    main_image = cv2.imread(main_image_path)\n",
    "    highlighted_image, merged_rectangles = highlight_rectangles(image,main_image)\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]    \n",
    "    for i, rect in enumerate(merged_rectangles):\n",
    "        x, y, w, h = rect\n",
    "        segment = main_image[y:y + h, x:x + w]\n",
    "        \n",
    "        output_path_segment = os.path.join(base_name, f'segment{i}.jpg')\n",
    "        cv2.imwrite(output_path_segment, segment)\n",
    "\n",
    "    output_path = os.path.join(base_name,'result4.jpg')\n",
    "    cv2.imwrite(output_path, highlighted_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running all code segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000016C2C11F310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000016C2C11FB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def facade_pattern(image_path):\n",
    "    output_image = run_rotation_fix(image_path)\n",
    "    output_image = detect_and_highlight(output_image,image_path)\n",
    "    output_image = pre_process_before_detection(output_image,image_path)\n",
    "    detection_and_segmentation(output_image,image_path)\n",
    "    \n",
    "\n",
    "def create_directory(image_path, base_directory):\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    directory_path = os.path.join(base_directory, base_name)\n",
    "    os.makedirs(directory_path, exist_ok=True)\n",
    "    facade_pattern(image_path)\n",
    "\n",
    "    shutil.copy(image_path, os.path.join(directory_path, os.path.basename(image_path)))\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_directory = os.getcwd()\n",
    "    testing_directory = os.path.join(base_directory, 'testing')\n",
    "    for filename in os.listdir(testing_directory):\n",
    "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "            image_path = os.path.join(testing_directory, filename)\n",
    "            #print(image_path)\n",
    "            create_directory(image_path, base_directory)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
